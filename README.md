# Papers
I like reading about Deep Learning and Computer Vision. Here I simply list the papers I read and that I want to read. Inspiration: [here](https://github.com/fregu856/papers).

## Taxonomy
I categorize papers by those I have read and those I have yet to read. Later, I will classify them based on if they are classics or not. Right now I am reading a mix of new and time tested papers.

‚úÖ Paper I have read.

üöÄ Exceptional read.

‚ùå Paper I have yet to read.

----

## List

### Self-supervised learning in Computer Vision
* ‚úÖ 03/2025: [DINOv2: Learning Robust Visual Features without Supervision](https://arxiv.org/abs/2304.07193)
* ‚úÖ 03/2025: [Cluster and Predict Latent Patches for Improved Masked Image Modeling](https://arxiv.org/abs/2502.08769)
* üöÄ 03/2025: [Simplifying DINO via Coding Rate Regularization](https://arxiv.org/abs/2502.10385)
* ‚úÖ 04/2025: [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)
* ‚úÖ 04/2025: [SimMIM: A Simple Framework for Masked Image Modeling](https://arxiv.org/abs/2111.09886)
* ‚ùå [Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning](https://arxiv.org/abs/2006.07733)
* ‚ùå [Mean Teachers are Better Role Models: Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results](https://arxiv.org/abs/1703.01780)
* ‚ùå [iBOT: Image BERT Pre-Training with Online Tokenizer](https://arxiv.org/abs/2111.07832)
* ‚ùå [Emerging Properties in Self-Supervised Vision Transformers](https://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)
* ‚ùå [Scaling Vision Pre-Training to 4K Resolution](https://arxiv.org/abs/2503.19903v1)
* ‚ùå [Generative Pretraining from Pixels](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)
* ‚ùå [MultiMAE: Multi-modal Multi-task Masked Autoencoders](https://arxiv.org/abs/2204.01678)
* ‚ùå [MOCA: Self-supervised Representation Learning by Predicting Masked Online Codebook Assignments](https://arxiv.org/abs/2307.09361)

### 3D Computer Vision
* ‚úÖ 03/2025: [VGGT: Visual Geometry Grounded Transformer](https://arxiv.org/abs/2503.11651)
* ‚úÖ 03/2025: [DKM: Dense Kernelized Feature Matching for Geometry Estimation](https://arxiv.org/abs/2202.00667)
* ‚úÖ 03/2025: [Pow3R: Empowering Unconstrained 3D Reconstruction with Camera and Scene Priors](https://arxiv.org/abs/2503.17316)
* ‚úÖ 03/2025: [DaD: Distilled Reinforcement Learning for Diverse Keypoint Detection](https://arxiv.org/abs/2503.07347)
* ‚ùå [MVSAnywhere: Zero-Shot Multi-View Stereo](https://nianticlabs.github.io/mvsanywhere/resources/MVSAnywhere.pdf)
* ‚ùå [Feat2GS: Probing Visual Foundation Models with Gaussian Splatting](https://arxiv.org/abs/2412.09606)
* ‚ùå [RoMa: Robust dense feature matching](https://arxiv.org/abs/2305.15404)
* ‚ùå [DeDoDe: Detect, don‚Äôt describe‚ÄîDescribe, don‚Äôt detect for local feature matching](https://arxiv.org/abs/2308.08479)
* ‚ùå [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934)
* ‚ùå [MASt3R-SfM: a Fully-Integrated Solution for Unconstrained Structure-from-Motion](https://arxiv.org/abs/2409.19152)
* ‚ùå [Feat2GS: Probing Visual Foundation Models with Gaussian Splatting](https://arxiv.org/abs/2412.09606)
* ‚ùå [AM-RADIO: Agglomerative Vision Foundation Model -- Reduce All Domains Into One](https://arxiv.org/abs/2312.06709)


### Diffusion
* ‚ùå [One-Minute Video Generation with Test-Time Training](https://arxiv.org/abs/2504.05298)

### General Computer Vision
* ‚úÖ 03/2025 [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
* ‚úÖ 03/2025 [Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction](https://arxiv.org/abs/2404.02905)
* ‚ùå [Segment Anything (SAM)](https://arxiv.org/abs/2304.02643)
* ‚ùå [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)
* ‚ùå [Learning Transferable Visual Models From Natural Language Supervision (CLIP)](https://arxiv.org/abs/2103.00020)
* ‚ùå [OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels](https://arxiv.org/abs/2502.20087v2)
* ‚ùå [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
* ‚ùå [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)
* ‚ùå [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)

### Geometric Deep Learning
* ‚ùå [Graph Attention Networks](https://arxiv.org/abs/1710.10903)

### NLP 
* ‚ùå [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

### General Deep Learning 
* ‚ùå [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)
* ‚ùå [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135)
* ‚ùå [Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets](https://arxiv.org/abs/2201.02177)

## Books
* ‚ùå [Understanding Deep Learning](https://udlbook.github.io/udlbook/)
* ‚ùå [Foundations of Computer Vision](https://visionbook.mit.edu/taxonomy.html#helmholtz-perception-as-inference)
* ‚ùå [Reinforcement Learning an Introduction](http://incompleteideas.net/book/RLbook2020.pdf)
