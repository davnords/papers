# Papers
I like reading about Deep Learning and Computer Vision. Here I simply list the papers I read and that I want to read. Inspiration: [here](https://github.com/fregu856/papers).

## Taxonomy
I categorize papers by those I have read and those I have yet to read. Later, I will classify them based on if they are classics or not. Right now I am reading a mix of new and time tested papers.

‚úÖ Paper I have read.

üöÄ Exceptional read.

‚ùå Paper I have yet to read.

----

## List

### Self-supervised learning in Computer Vision
* ‚úÖ 03/2025: [DINOv2: Learning Robust Visual Features without Supervision](https://arxiv.org/abs/2304.07193)
* ‚úÖ 03/2025: [Cluster and Predict Latent Patches for Improved Masked Image Modeling](https://arxiv.org/abs/2502.08769)
* üöÄ 03/2025: [Simplifying DINO via Coding Rate Regularization](https://arxiv.org/abs/2502.10385)
* ‚úÖ 04/2025: [Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)
* ‚úÖ 04/2025: [SimMIM: A Simple Framework for Masked Image Modeling](https://arxiv.org/abs/2111.09886)
* ‚úÖ 05/2025: [iBOT: Image BERT Pre-Training with Online Tokenizer](https://arxiv.org/abs/2111.07832)
* ‚úÖ 06/2025: [Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning](https://arxiv.org/abs/2006.07733)
* ‚ùå [Mean Teachers are Better Role Models: Weight-Averaged Consistency Targets Improve Semi-Supervised Deep Learning Results](https://arxiv.org/abs/1703.01780)
* ‚ùå [Emerging Properties in Self-Supervised Vision Transformers](https://openaccess.thecvf.com/content/ICCV2021/html/Caron_Emerging_Properties_in_Self-Supervised_Vision_Transformers_ICCV_2021_paper.html)
* ‚ùå [Scaling Vision Pre-Training to 4K Resolution](https://arxiv.org/abs/2503.19903v1)
* ‚ùå [Generative Pretraining from Pixels](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)
* ‚ùå [MultiMAE: Multi-modal Multi-task Masked Autoencoders](https://arxiv.org/abs/2204.01678)
* ‚ùå [MOCA: Self-supervised Representation Learning by Predicting Masked Online Codebook Assignments](https://arxiv.org/abs/2307.09361)
* ‚ùå [Scaling Language-Free Visual Representation Learning](https://arxiv.org/abs/2504.01017)


### 3D Computer Vision
* ‚úÖ 03/2025: [VGGT: Visual Geometry Grounded Transformer](https://arxiv.org/abs/2503.11651)
* ‚úÖ 03/2025: [DKM: Dense Kernelized Feature Matching for Geometry Estimation](https://arxiv.org/abs/2202.00667)
* ‚úÖ 03/2025: [Pow3R: Empowering Unconstrained 3D Reconstruction with Camera and Scene Priors](https://arxiv.org/abs/2503.17316)
* ‚úÖ 03/2025: [DaD: Distilled Reinforcement Learning for Diverse Keypoint Detection](https://arxiv.org/abs/2503.07347)
* ‚ùå [MVSAnywhere: Zero-Shot Multi-View Stereo](https://nianticlabs.github.io/mvsanywhere/resources/MVSAnywhere.pdf)
* ‚ùå [Feat2GS: Probing Visual Foundation Models with Gaussian Splatting](https://arxiv.org/abs/2412.09606)
* ‚ùå [RoMa: Robust dense feature matching](https://arxiv.org/abs/2305.15404)
* ‚ùå [DeDoDe: Detect, don‚Äôt describe‚ÄîDescribe, don‚Äôt detect for local feature matching](https://arxiv.org/abs/2308.08479)
* ‚ùå [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934)
* ‚ùå [MASt3R-SfM: a Fully-Integrated Solution for Unconstrained Structure-from-Motion](https://arxiv.org/abs/2409.19152)
* ‚ùå [Feat2GS: Probing Visual Foundation Models with Gaussian Splatting](https://arxiv.org/abs/2412.09606)
* ‚ùå [AM-RADIO: Agglomerative Vision Foundation Model -- Reduce All Domains Into One](https://arxiv.org/abs/2312.06709)
* ‚ùå [RayZer: A Self-supervised Large View Synthesis Model](https://arxiv.org/abs/2505.00702)
* ‚ùå [Cross-View Completion Models are Zero-shot Correspondence Estimators](https://arxiv.org/abs/2412.09072)

### Image Genearation / Diffusion
* ‚úÖ 05/2025: [Consistency Models](https://arxiv.org/abs/2303.01469)
* ‚ùå [One-Minute Video Generation with Test-Time Training](https://arxiv.org/abs/2504.05298)
* ‚ùå [Neural Discrete Representation Learning](https://arxiv.org/abs/1711.00937)
* ‚ùå [Taming Transformers for High-Resolution Image Synthesis](https://arxiv.org/abs/2012.09841)
* ‚ùå [SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation](https://arxiv.org/pdf/2503.09641)

### General Computer Vision
* ‚úÖ 03/2025: [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)
* ‚úÖ 03/2025: [Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction](https://arxiv.org/abs/2404.02905)
* ‚ùå [Segment Anything (SAM)](https://arxiv.org/abs/2304.02643)
* ‚ùå [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)
* ‚ùå [Learning Transferable Visual Models From Natural Language Supervision (CLIP)](https://arxiv.org/abs/2103.00020)
* ‚ùå [OverLoCK: An Overview-first-Look-Closely-next ConvNet with Context-Mixing Dynamic Kernels](https://arxiv.org/abs/2502.20087v2)
* ‚ùå [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)
* ‚ùå [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)
* ‚ùå [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)
* ‚ùå [ResMLP: Feedforward networks for image classification with data-efficient training](https://arxiv.org/abs/2105.03404)
* ‚ùå [MLP-Mixer: An all-MLP Architecture for Vision](https://arxiv.org/pdf/2105.01601)
* ‚ùå [Scaling Vision Transformers to 22 Billion Parameters](https://arxiv.org/abs/2302.05442)
* ‚úÖ [Better plain ViT baselines for ImageNet-1k](https://arxiv.org/pdf/2205.01580)
* ‚ùå [Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design](https://proceedings.neurips.cc/paper_files/paper/2023/file/3504a4fa45685d668ce92797fbbf1895-Paper-Conference.pdf)
* ‚ùå [Vision Transformers Don't Need Trained Registers](https://www.arxiv.org/abs/2506.08010)

### Geometric Deep Learning
* ‚ùå [Graph Attention Networks](https://arxiv.org/abs/1710.10903)

### NLP 
* ‚úÖ 04/2025: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)

### General Deep Learning 
* ‚ùå [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)
* ‚ùå [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135)
* ‚ùå [Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets](https://arxiv.org/abs/2201.02177)
* ‚ùå [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)
* ‚ùå [On the Biology of LLMs](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)
 
## Books
* ‚ùå [Understanding Deep Learning](https://udlbook.github.io/udlbook/)
* ‚ùå [Foundations of Computer Vision](https://visionbook.mit.edu/taxonomy.html#helmholtz-perception-as-inference)
* ‚ùå [Reinforcement Learning an Introduction](http://incompleteideas.net/book/RLbook2020.pdf)

## Blocks
* ‚ùå [Generative modelling in latent space](https://sander.ai/2025/04/15/latents.html)
* ‚ùå [Noise schedules considered harmful](https://sander.ai/2024/06/14/noise-schedules.html)
* ‚ùå [Diffusion is spectral autoregression](https://sander.ai/2024/09/02/spectral-autoregression.html)
